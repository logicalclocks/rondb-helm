apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: rdrs
  namespace: {{ .Release.Namespace }}
spec:
  serviceName: rdrs
  replicas: {{ .Values.clusterSize.minNumRdrs }}
  selector:
    # Used by the Deployment to select and manage existing pods with the specified label
    matchLabels:
      rondbService: rdrs
  template:
    metadata:
      # Used to apply labels to all pods created by the Deployment
      labels:
        rondbService: rdrs
    spec:
      {{- include "rondb.imagePullSecrets" . | indent 6 }}
      affinity:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          # Preferred on different node
          - weight: 90
            podAffinityTerm:
              labelSelector:
                matchExpressions:
                - key: rondbService
                  operator: In
                  values:
                  - rdrs
              topologyKey: kubernetes.io/hostname
          # Preferred in different zone
          - weight: 60
            podAffinityTerm:
              labelSelector:
                matchExpressions:
                - key: rondbService
                  operator: In
                  values:
                  - rdrs
              topologyKey: topology.kubernetes.io/zone
      initContainers:
      - name: datanode-dependency-check
        image: {{ include "image_registry" . }}rondb-standalone:{{ .Values.image.tag }}
        command:
        - /bin/bash
        - -c
        - |
          until nslookup mgmds-0.mgmd.{{ .Release.Namespace }}.svc.cluster.local; do
            echo "Waiting for mgmds-0.mgmd.{{ .Release.Namespace }}.svc.cluster.local to be resolvable..."
            sleep $(((RANDOM % 2)+2))
          done

          # Wait until data node is ready
          until ./docker/rondb_standalone/healthcheck.sh mgmds-0.mgmd.{{ .Release.Namespace }}.svc.cluster.local:1186 1; do
            echo "Dependency healthcheck of ndbmtd failed. Retrying in a bit."
            sleep $(((RANDOM % 2)+2))
          done
      containers:
      - name: rdrs
        image: {{ include "image_registry" . }}rondb-standalone:{{ .Values.image.tag }}
        command:
          - /bin/bash
          - -c
          - ./docker/rondb_standalone/entrypoints/main.sh rdrs -config=/srv/hops/mysql-cluster/rest_api.json
        ports:
          - containerPort: 4406
          - containerPort: 5406
        resources:
          limits:
            cpu: {{ .Values.resources.limits.cpus.ndbmtds }}
            memory: {{ .Values.resources.limits.memory.ndbmtds }}
          requests:
            cpu: {{ .Values.resources.requests.cpus.ndbmtds }}
            memory: {{ .Values.resources.requests.memory.ndbmtds }}
        env:
          - name: HOST_GROUP_ID
            value: "0"
          - name: POD_NAME
            valueFrom:
              fieldRef:
                fieldPath: metadata.name
        volumeMounts:
        # Only mount single file, otherwise entire directory becomes read-only
        - name: rondb-configs
          mountPath: /srv/hops/mysql-cluster/rest_api.json
          subPath: rest_api.json
      # StatefulSets work with PVCs to create a dedicated persistent volume for
      # each pod replica, ensuring that a pod always re-attaches to the same data
      # even if it is rescheduled to a different node.
      volumes:
      - name: rondb-configs
        configMap:
          name: rondb-configs
---
apiVersion: v1
kind: Service
metadata:
  # Match the spec.serviceName
  name: rdrs
  namespace: {{ .Release.Namespace }}
spec:
  # Headless service for individual DNS records for the pods
  clusterIP: None
  # So we do not rely on the readiness probe to connect to the MGMd
  publishNotReadyAddresses: true
  # Match the spec.template.metadata.labels of the StatefulSet
  selector:
    rondbService: rdrs
  ports:
    - name: rest
      protocol: TCP
      port: 4406
      targetPort: 4406
    - name: grpc
      protocol: TCP
      port: 5406
      targetPort: 5406
---
{{ if
    and (gt (.Values.clusterSize.minNumRdrs | int) 0)
    (not (eq .Values.clusterSize.minNumRdrs .Values.clusterSize.maxNumRdrs))
}}
# Cannot autosscale from 0 since no metrics to measure
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: rdrs
  namespace: {{ .Release.Namespace }}
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: StatefulSet
    name: rdrs
  minReplicas: {{ .Values.clusterSize.minNumRdrs }}
  maxReplicas: {{ .Values.clusterSize.maxNumRdrs }}
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
{{ end }}
